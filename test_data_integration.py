#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®æ•´åˆåŠŸèƒ½
æ¼”ç¤ºå¦‚ä½•å°†æ‰€æœ‰æ•°æ®è½¬æ¢ä¸ºAIå‹å¥½çš„å‘é‡æ ¼å¼
"""

import logging
import sys
import os

sys.path.insert(0, os.path.dirname(__file__))

from utils.gas_monitor import GasFeeMonitor
from utils.multi_source_fetcher import MultiSourceDataFetcher
from utils.sentiment_analyzer import MarketSentimentAnalyzer
from utils.data_integrator import DataIntegrator
import config

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "="*80)
    print("ğŸ”„ æ•°æ®æ•´åˆæµ‹è¯• - å°†å¤šæºæ•°æ®è½¬æ¢ä¸ºAIå‘é‡")
    print("="*80)
    
    # 1. è·å–å„ç±»æ•°æ®
    print("\nğŸ“Š æ­¥éª¤1: è·å–åŸå§‹æ•°æ®...")
    
    # Gasæ•°æ®
    gas_monitor = GasFeeMonitor(etherscan_key=getattr(config, 'ETHERSCAN_API_KEY', ''))
    gas_conditions = gas_monitor.check_trading_conditions()
    
    # Kçº¿æ•°æ®
    fetcher = MultiSourceDataFetcher()
    kline_df = fetcher.aggregate_and_validate("BTCUSDT", limit=20)
    
    # å¸‚åœºæƒ…ç»ª
    analyzer = MarketSentimentAnalyzer()
    market_sentiment = analyzer.get_comprehensive_sentiment("BTC")
    
    # 2. æ•´åˆæ•°æ®
    print("\nğŸ”„ æ­¥éª¤2: æ•´åˆæ•°æ®ä¸ºå‘é‡...")
    integrator = DataIntegrator()
    
    integrated = integrator.integrate_all(
        gas_data=gas_conditions,
        kline_df=kline_df,
        market_sentiment=market_sentiment
    )
    
    # 3. å±•ç¤ºç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š æ•´åˆç»“æœ")
    print("="*80)
    
    print(f"\nâœ… ç‰¹å¾ç»´åº¦: {integrated['feature_count']}")
    print(f"âœ… æ—¶é—´æˆ³: {integrated['timestamp']}")
    
    # æ˜¾ç¤ºç‰¹å¾å‘é‡
    print("\nğŸ“ˆ ç‰¹å¾å‘é‡:")
    print("-" * 80)
    features = integrated['features']
    names = integrated['feature_names']
    
    for i, (name, value) in enumerate(zip(names, features)):
        if isinstance(value, float):
            print(f"  [{i:2d}] {name:25s} = {value:12.6f}")
        else:
            print(f"  [{i:2d}] {name:25s} = {value:12}")
    
    # æ˜¾ç¤ºæ‘˜è¦
    print("\nğŸ“‹ æ•°æ®æ‘˜è¦:")
    print("-" * 80)
    summary = integrated['summary']
    for key, value in summary.items():
        print(f"  {key:20s}: {value}")
    
    # 4. è½¬æ¢ä¸ºä¸åŒæ ¼å¼
    print("\n" + "="*80)
    print("ğŸ”§ æ ¼å¼è½¬æ¢ç¤ºä¾‹")
    print("="*80)
    
    # Numpyæ•°ç»„
    print("\n1ï¸âƒ£  Numpyæ•°ç»„æ ¼å¼:")
    np_array = integrator.to_numpy_array(integrated)
    print(f"   Shape: {np_array.shape}")
    print(f"   Dtype: {np_array.dtype}")
    print(f"   å‰10ä¸ªå€¼: {np_array[:10]}")
    
    # å­—å…¸æ ¼å¼
    print("\n2ï¸âƒ£  å­—å…¸æ ¼å¼ï¼ˆéƒ¨åˆ†ï¼‰:")
    dict_format = integrator.to_dict(integrated)
    for i, (k, v) in enumerate(list(dict_format.items())[:5]):
        print(f"   '{k}': {v}")
    
    # AI Promptæ ¼å¼
    print("\n3ï¸âƒ£  AI Promptæ ¼å¼:")
    print("-" * 80)
    prompt = integrator.format_for_ai_prompt(integrated)
    print(prompt)
    
    # 5. ä¿å­˜ç»“æœ
    print("\n" + "="*80)
    print("ğŸ’¾ ä¿å­˜ç»“æœ")
    print("="*80)
    
    import json
    
    # ä¿å­˜ä¸ºJSON
    output_file = "data/integrated_features.json"
    with open(output_file, 'w') as f:
        json.dump(integrated, f, indent=2)
    
    print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜AI Prompt
    prompt_file = "data/ai_prompt.txt"
    with open(prompt_file, 'w') as f:
        f.write(prompt)
    
    print(f"âœ… AI Promptå·²ä¿å­˜åˆ°: {prompt_file}")
    
    # 6. ä½¿ç”¨å»ºè®®
    print("\n" + "="*80)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®")
    print("="*80)
    
    print("""
1ï¸âƒ£  å‘é€ç»™AIæ¨¡å‹:
   prompt = integrator.format_for_ai_prompt(integrated)
   # ç„¶åå°†promptå‘é€ç»™Grok/Gemini/DeepSeek

2ï¸âƒ£  æœºå™¨å­¦ä¹ è®­ç»ƒ:
   X = integrator.to_numpy_array(integrated)
   # ç”¨äºsklearn/tensorflowç­‰æ¨¡å‹

3ï¸âƒ£  æ•°æ®åˆ†æ:
   df = pd.DataFrame([integrator.to_dict(integrated)])
   # ç”¨pandasè¿›è¡Œåˆ†æ

4ï¸âƒ£  å®æ—¶å†³ç­–:
   if integrated['summary']['gas_suitable']:
       if integrated['summary']['ai_consensus'] == 'bullish':
           # æ‰§è¡Œä¹°å…¥é€»è¾‘
           pass
    """)
    
    # 7. æ•°æ®ç»Ÿè®¡
    print("\n" + "="*80)
    print("ğŸ“Š æ•°æ®ç»Ÿè®¡")
    print("="*80)
    
    feature_groups = {
        'Gasæ•°æ®': ['eth_gas_gwei', 'btc_fee_sat', 'eth_tradeable', 'btc_tradeable'],
        'Kçº¿æ•°æ®': ['current_price', 'price_change_pct', 'avg_volume', 'volatility', 'trend'],
        'æ–°é—»æƒ…ç»ª': ['news_score', 'news_pos_ratio', 'news_neg_ratio', 'news_count', 'news_sentiment'],
        'å¸‚åœºæƒ…ç»ª': ['market_sentiment_score', 'market_confidence', 'fear_greed_index', 'market_sentiment_label'],
        'AIé¢„æµ‹': ['ai_avg_confidence', 'ai_up_count', 'ai_down_count', 'ai_agreement_ratio', 'ai_consensus']
    }
    
    dict_data = integrator.to_dict(integrated)
    
    for group_name, features in feature_groups.items():
        print(f"\n{group_name}:")
        available = sum(1 for f in features if f in dict_data and dict_data[f] != 0)
        print(f"  å¯ç”¨ç‰¹å¾: {available}/{len(features)}")
        for feat in features:
            if feat in dict_data:
                val = dict_data[feat]
                if isinstance(val, float):
                    print(f"    {feat}: {val:.4f}")
                else:
                    print(f"    {feat}: {val}")
    
    print("\n" + "="*80)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("="*80)
    
    print(f"""
æ€»ç»“:
âœ… æˆåŠŸå°†å¤šæºæ•°æ®æ•´åˆä¸º {integrated['feature_count']} ç»´ç‰¹å¾å‘é‡
âœ… æ•°æ®å·²ä¿å­˜åˆ° data/ ç›®å½•
âœ… å¯ç›´æ¥ç”¨äºAIæ¨¡å‹æˆ–æœºå™¨å­¦ä¹ 

ä¼˜åŠ¿:
1. çœToken: å°†å¤æ‚æ•°æ®å‹ç¼©ä¸ºå‘é‡
2. æ˜“ç†è§£: ç‰¹å¾åç§°æ¸…æ™°ï¼Œæœ‰æ•°æ®æ‘˜è¦
3. å¤šæ ¼å¼: æ”¯æŒnumpyã€dictã€promptç­‰æ ¼å¼
4. å®æ—¶æ€§: åŒ…å«æ—¶é—´æˆ³ï¼Œå¯è¿½æº¯
    """)


if __name__ == "__main__":
    main()
